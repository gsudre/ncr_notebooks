{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to use the multiplex sample as replication (or negation) sample for the CNV findings in the simplex cohort. In other words, we want to check that whatever we found in the simplex cohort is not true for the multiplex cohort. So, no samples in the simplex cohort should be used in the multiplex findings. For that, I'll use the samples_multiplex_only.txt, which means that the samples are only in multiplex and not in simplex (151 samples raw).\n",
    "\n",
    "Let's start the preprocessing then. First, make sure that no weird samples need to be thrown out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique samples: 153\n",
      "Unique families: 20\n",
      "Unique children: 80\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "ped_files = ['/data/sudregp/multiplex_simplex/multiplex.ped']\n",
    "wes_prefix = ['CLIA', 'CCGO', 'WPS']\n",
    "fid = open('/data/sudregp/cnv/xhmm_clean2/samples.txt', 'r')\n",
    "exclude_list = [line.rstrip() for line in fid]\n",
    "fid.close()\n",
    "\n",
    "trios = []\n",
    "affected = []\n",
    "controls = []\n",
    "samples = []\n",
    "famids = []\n",
    "for ped_file in ped_files:\n",
    "    fid = open(ped_file, 'r')\n",
    "    for line in fid:\n",
    "        famid, sid, fa, mo, sex, aff = line.rstrip().split('\\t')\n",
    "        # if the current ID and its parents have WES data, and the sample is \n",
    "        # not in yet\n",
    "        if (fa.split('_')[0] in wes_prefix and\n",
    "            mo.split('_')[0] in wes_prefix and\n",
    "            sid.split('_')[0] in wes_prefix and\n",
    "            sid not in samples and\n",
    "            (sid not in exclude_list or fa not in exclude_list or mo not in exclude_list)):\n",
    "            fam = {}\n",
    "            fam['child'] = sid\n",
    "            if aff == '1':\n",
    "                affected.append(sid)\n",
    "            else:\n",
    "                controls.append(sid)\n",
    "            fam['father'] = fa\n",
    "            fam['mother'] = mo\n",
    "            fam['famid'] = famid\n",
    "            trios.append(fam)\n",
    "            samples += [sid, fa, mo]\n",
    "            famids.append(famid)\n",
    "    fid.close()\n",
    "samples = set(samples)\n",
    "famids = set(famids)\n",
    "kids = set(affected + controls)\n",
    "\n",
    "print 'Unique samples:', len(samples)\n",
    "print 'Unique families:', len(famids)\n",
    "print 'Unique children:', len(kids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, basically we'll looking at everyone in the multiplex pedigree, provided they're not in the simplex analysis and have parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = open('/data/sudregp/multiplex_simplex/xhmm_replication/samples.txt', 'w')\n",
    "for s in samples:\n",
    "    fid.write(s + '\\n')\n",
    "fid.close()\n",
    "\n",
    "fid = open('/data/sudregp/multiplex_simplex/xhmm_replication/kid_samples.txt', 'w')\n",
    "for s in kids:\n",
    "    fid.write(s + '\\n')\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting a very similar analysis we did for xhmm_ximplex_clean of today's date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in terminal\n",
    "exome_targets='/data/NCR_SBRB/simplex/SeqCapEZ_Exome_v3.0_Design_Annotation_files/SeqCap_EZ_Exome_v3_hg19_capture_targets.bed'\n",
    "gatk_memory=\"50g\"\n",
    "ref_fa='/fdb/GATK_resource_bundle/hg19-2.8/ucsc.hg19.fasta'\n",
    "out_dir='/data/sudregp/multiplex_simplex/xhmm_replication/'\n",
    "\n",
    "cd $out_dir\n",
    "module load GATK\n",
    "module load XHMM\n",
    "\n",
    "GATK -m ${gatk_memory} GCContentByInterval -L ${exome_targets} -R ${ref_fa} -o ./DATA.locus_GC.txt\n",
    "cat ./DATA.locus_GC.txt | awk '{if ($2 < 0.1 || $2 > 0.9) print $1}' > ./extreme_gc_targets.txt\n",
    "\n",
    "# merging all subjects in the directory\n",
    "while read s; do\n",
    "    cp ../xhmm/${s}* .\n",
    "done < samples.txt\n",
    "ls -1 *.sample_interval_summary > depth_list.txt;\n",
    "cp ../xhmm/params.txt .\n",
    "\n",
    "xhmm --mergeGATKdepths --GATKdepthsList=depth_list.txt -o ./DATA.RD.txt;\n",
    "\n",
    "# this does the same thing as the XHMM script, but it actually works in parsing \n",
    "# the base pair start and ends\n",
    "cat ${exome_targets} | awk 'BEGIN{OFS=\"\\t\"; print \"#CHR\\tBP1\\tBP2\\tID\"}{print $1, $2, $3, NR}' > ./EXOME.targets.reg\n",
    "\n",
    "module load plinkseq\n",
    "pseq . loc-load --locdb ./EXOME.targets.LOCDB --file ./EXOME.targets.reg --group targets \\\n",
    "    --out ./EXOME.targets.LOCDB.loc-load --noweb\n",
    "\n",
    "# this has the same effect as the suggested command, but it actually works\n",
    "pseq . loc-stats --locdb ./EXOME.targets.LOCDB --group targets --seqdb ./seqdb.hg19 --noweb | \\\n",
    "    awk '{if (NR > 1) { print  $4, $10 }}' | sed 's/\\.\\./-/' - > ./DATA.locus_complexity.txt\n",
    "\n",
    "cat ./DATA.locus_complexity.txt | awk '{if ($2 > 0.25) print $1}' > ./low_complexity_targets.txt\n",
    "\n",
    "xhmm --matrix -r ./DATA.RD.txt --centerData --centerType target \\\n",
    "-o ./DATA.filtered_centered.RD.txt \\\n",
    "--outputExcludedTargets ./DATA.filtered_centered.RD.txt.filtered_targets.txt \\\n",
    "--outputExcludedSamples ./DATA.filtered_centered.RD.txt.filtered_samples.txt \\\n",
    "--excludeTargets ./extreme_gc_targets.txt --excludeTargets ./low_complexity_targets.txt \\\n",
    "--minTargetSize 10 --maxTargetSize 10000 \\\n",
    "--minMeanTargetRD 10 --maxMeanTargetRD 500 \\\n",
    "--minMeanSampleRD 25 --maxMeanSampleRD 200 \\\n",
    "--maxSdSampleRD 150\n",
    "\n",
    "xhmm --PCA -r ./DATA.filtered_centered.RD.txt --PCAfiles ./DATA.RD_PCA\n",
    "\n",
    "xhmm --normalize -r ./DATA.filtered_centered.RD.txt --PCAfiles ./DATA.RD_PCA \\\n",
    "--normalizeOutput ./DATA.PCA_normalized.txt \\\n",
    "--PCnormalizeMethod PVE_mean --PVE_mean_factor 0.7\n",
    "\n",
    "xhmm --matrix -r ./DATA.PCA_normalized.txt --centerData --centerType sample --zScoreData \\\n",
    "-o ./DATA.PCA_normalized.filtered.sample_zscores.RD.txt \\\n",
    "--outputExcludedTargets ./DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_targets.txt \\\n",
    "--outputExcludedSamples ./DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_samples.txt \\\n",
    "--maxSdTargetRD 30\n",
    "\n",
    "xhmm --matrix -r ./DATA.RD.txt \\\n",
    "--excludeTargets ./DATA.filtered_centered.RD.txt.filtered_targets.txt \\\n",
    "--excludeTargets ./DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_targets.txt \\\n",
    "--excludeSamples ./DATA.filtered_centered.RD.txt.filtered_samples.txt \\\n",
    "--excludeSamples ./DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_samples.txt \\\n",
    "-o ./DATA.same_filtered.RD.txt\n",
    "\n",
    "xhmm --discover -p params.txt -r ./DATA.PCA_normalized.filtered.sample_zscores.RD.txt \\\n",
    "    -R ./DATA.same_filtered.RD.txt -c ./DATA.xcnv -a ./DATA.aux_xcnv -s ./DATA\n",
    "\n",
    "xhmm --genotype -p params.txt -r ./DATA.PCA_normalized.filtered.sample_zscores.RD.txt \\\n",
    "    -R ./DATA.same_filtered.RD.txt -g ./DATA.xcnv -F $ref_fa -v ./DATA.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# junk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if anyone got removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw---- 1 sudregp sudregp 0 Jan 25 15:37 DATA.filtered_centered.RD.txt.filtered_samples.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ~/data/multiplex_simplex/xhmm/\n",
    "ls -ltr DATA.filtered_centered.RD.txt.filtered_samples.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
