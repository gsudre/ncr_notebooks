{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my first try with CANOES (http://www.columbia.edu/~ys2411/canoes/). From the get-go, we'll use the trimmed samples. Its first step takes a LONG time, so let's do it per sample, and then concatenate it. I tested it before with two samples, and it worked fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ~/data/cnv/trimmed/canoes\n",
    "cp ../conifer/samples.txt .\n",
    "probes=\"/data/NCR_SBRB/simplex/SeqCapEZ_Exome_v3.0_Design_Annotation_files/SeqCap_EZ_Exome_v3_hg19_capture_targets.bed\"\n",
    "\n",
    "while read s; do\n",
    "    echo \"cd ~/data/cnv/trimmed/canoes/; bedtools multicov -bams ../BAM/${s}.bam -bed $probes -q 20 > ${s}.reads.txt\" >> swarm.reads;\n",
    "done < samples.txt\n",
    "swarm --time 2-00:00:00 -f swarm.reads --job-name canoes --logdir trash --module bedtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to combine them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# terminal\n",
    "module load GATK\n",
    "exome_targets=\"/data/NCR_SBRB/simplex/SeqCapEZ_Exome_v3.0_Design_Annotation_files/SeqCap_EZ_Exome_v3_hg19_capture_targets.bed\"\n",
    "ref_fa='/fdb/igenomes/Homo_sapiens/UCSC/hg19/Sequence/WholeGenomeFasta/genome.fa'\n",
    "java -Xmx2000m -Djava.io.tmpdir=/lscratch/${SLURM_JOBID} -jar $GATK_JAR \\\n",
    "    -T GCContentByInterval -L ${exome_targets} -R $ref_fa -o gc.txt\n",
    "    \n",
    "for f in `ls CLIA*reads.txt`; do cut -f 5 ${f} > ${f}.cut; done\n",
    "# check that they all ran fine\n",
    "wc -l *cut\n",
    "\n",
    "paste *cut > samples.reads.txt.cut\n",
    "cut -f 1,2,3 CLIA_400142.reads.txt > first_columns.txt\n",
    "paste first_columns.txt samples.reads.txt.cut > canoes.reads.txt\n",
    "ls -1 C*cut | cut -d\".\" -f 1 > sample_names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# but really, in terminal\n",
    "\n",
    "gc <- read.table(\"gc.txt\")$V2\n",
    "canoes.reads <- read.table(\"canoes.reads.txt\")\n",
    "sample.names = read.table(\"sample_names.txt\")\n",
    "sample.names = sapply(sample.names, as.character)\n",
    "names(canoes.reads) <- c(\"chromosome\", \"start\", \"end\", sample.names)\n",
    "\n",
    "target <- seq(1, nrow(canoes.reads))\n",
    "canoes.reads <- cbind(target, gc, canoes.reads)\n",
    "\n",
    "source('/data/NCR_SBRB/software/CANOES.R')\n",
    "xcnv.list <- vector('list', length(sample.names))\n",
    "for (i in 1:length(sample.names)){\n",
    "    print(i)\n",
    "    xcnv.list[[i]] <- CallCNVs(sample.names[i], canoes.reads)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to parallelize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(parallel)\n",
    "cl = makeCluster(12, type='FORK')\n",
    "# clusterEvalQ(cl, source('/data/NCR_SBRB/software/CANOES.R'))\n",
    "xcnv.list = parLapply(cl, sample.names, CallCNVs, canoes.reads)\n",
    "stopCluster(cl)\n",
    "\n",
    "xcnvs <- do.call('rbind', xcnv.list)\n",
    "write.table(xcnvs, file='~/data/cnv/trimmed/canoes/cnvs.txt', row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The webpage (http://www.columbia.edu/~ys2411/canoes/) also shows some examples of how to do genotyping for each sample, but I don't think that's necessary? Maybe..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# junk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's disheartening... do we have anyone ready?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples ready:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd ~/data/cnv/mdts\n",
    "\n",
    "echo \"Samples ready:\"\n",
    "while read s; do\n",
    "    if [ -e /data/NCR_SBRB/ADHDQTL/GATK/BAM/${s}/${s}_trimmed_sorted_RG_markduplicate_recalibrated.bam ]; then\n",
    "        echo $s;\n",
    "    fi;\n",
    "done < samples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright then... we'll need to re-run everyone.\n",
    "\n",
    "Since we're re-running this, it'll be interesting to try different BAM pipelines:\n",
    "\n",
    "1. Standard (BWA MEM + Picard + Base recalibration)\n",
    "2. No base recalibration (BWA MEM + Picard)\n",
    "3. mrsFast (as suggested in CONIFER)\n",
    "\n",
    "Running mrsFast might not be worth it, and it's somewhat older software (2014). So, if we end up doing it, we might as well run some of their own CNV tools (http://mrcanavar.sourceforge.net/manual.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /data/NCR_SBRB/simplex\n",
    "\n",
    "while read s; do\n",
    "    echo \"bash ~/autodenovo/gatk_upToSingleCalls.sh $s\" >> swarm.single;\n",
    "done < ~/data/cnv/mdts/samples.txt;\n",
    "\n",
    "[sudregp@cn2350 simplex]$ head swarm.single\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400185\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400200\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400193\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400195\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400148\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400188\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400189\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400191\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400181\n",
    "bash ~/autodenovo/gatk_upToSingleCalls.sh CLIA_400203\n",
    "\n",
    "[sudregp@cn2350 simplex]$ wc -l swarm.single\n",
    "84 swarm.single\n",
    "[sudregp@cn2350 simplex]$ swarm -f swarm.single -t 32 -g 120 --job-name gatk_single --logdir trash --time=48:00:00 --gres=lscratch:1\n",
    "00\n",
    "63296498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "library(MDTS, lib='~/R')\n",
    "library(BSgenome.Hsapiens.UCSC.hg19)\n",
    "genome = BSgenome.Hsapiens.UCSC.hg19\n",
    "map_file = \"chr1.map.bw\"\n",
    "setwd('~/data/cnv/mdts')\n",
    "pD = getMetaData(\"simplex84.ped\")\n",
    "bins = calcBins(pD, n=5, readLength=100, medianCoverage=150,\n",
    "                minimumCoverage=5, genome=genome, mappabilityFile=map_file)\n",
    "\n",
    "# it might be possible to make this go faster if we split the genome by chromosomes?\n",
    "\n",
    "counts = calcCounts(pD, bins, rl=100)\n",
    "mCounts <- normalizeCounts(counts, bins)\n",
    "md <- calcMD(mCounts, pD)\n",
    "cbs <- segmentMD(md=md, bins=bins)\n",
    "denovo <- denovoDeletions(cbs, mCounts, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEED TO DOWNLOAD MAPABILITY FILES FOR ALL CHROMOSOMES. SOMETHING LIKE THIS: http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeMapability/. BUT SHOULD HECK THE QC FILES FOR A BETTER READ LENGTH ESTIMATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique samples: 84\n",
      "Unique families: 19\n",
      "Unique children: 46\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "ped_files = ['/data/sudregp/multiplex_simplex/simplex.ped']\n",
    "wes_prefix = ['CLIA', 'CCGO', 'WPS']\n",
    "# fid = open('/home/sudregp/data/multiplex_simplex/samples_simplex_all.txt', 'r')\n",
    "# exclude_list = [line.rstrip() for line in fid]\n",
    "# fid.close()\n",
    "\n",
    "# no controls/affected pair for comparison\n",
    "exclude_list = ['CLIA_400165', 'CLIA_400164', 'CLIA_400155', 'CLIA_400146',\n",
    "                'CLIA_400145', 'CLIA_400126', 'CLIA_400207', 'CLIA_400208',\n",
    "                'CLIA_400209']\n",
    "# missing one parent\n",
    "exclude_list += ['CLIA_400169', 'CLIA_400168']\n",
    "# family 9030\n",
    "exclude_list += ['CCGO_800978', 'CCGO_800977', 'CCGO_800976', 'CCGO_800979',\n",
    "                 'CCGO_800980', 'CLIA_400067']\n",
    "\n",
    "trios = []\n",
    "affected = []\n",
    "controls = []\n",
    "samples = []\n",
    "famids = []\n",
    "sexes = {}\n",
    "for ped_file in ped_files:\n",
    "    fid = open(ped_file, 'r')\n",
    "    for line in fid:\n",
    "        famid, sid, fa, mo, sex, aff = line.rstrip().split('\\t')\n",
    "        # if the current ID and its parents have WES data, and the sample is \n",
    "        # not in yet\n",
    "        if (fa.split('_')[0] in wes_prefix and\n",
    "            mo.split('_')[0] in wes_prefix and\n",
    "            sid.split('_')[0] in wes_prefix and\n",
    "            sid not in samples and\n",
    "            (sid not in exclude_list or fa not in exclude_list or mo not in exclude_list)):\n",
    "            fam = {}\n",
    "            fam['child'] = sid\n",
    "            if aff == '1':\n",
    "                affected.append(sid)\n",
    "            else:\n",
    "                controls.append(sid)\n",
    "            fam['father'] = fa\n",
    "            fam['mother'] = mo\n",
    "            fam['famid'] = famid\n",
    "            sexes[sid] = sex\n",
    "            trios.append(fam)\n",
    "            samples += [sid, fa, mo]\n",
    "            famids.append(famid)\n",
    "    fid.close()\n",
    "samples = set(samples)\n",
    "famids = set(famids)\n",
    "kids = set(affected + controls)\n",
    "good_kids = kids\n",
    "\n",
    "print 'Unique samples:', len(samples)\n",
    "print 'Unique families:', len(famids)\n",
    "print 'Unique children:', len(kids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fid = open('/data/sudregp/cnv/mdts/simplex84.ped', 'w')\n",
    "fid.write('subj_id\\tfamily_id\\tfather_id\\tmother_id\\tgender\\tbam_path\\n')\n",
    "for trio in trios:\n",
    "    fid.write('\\t'.join([trio['child'], trio['famid'], trio['father'],\n",
    "                         trio['mother'], sexes[trio['child']],\n",
    "                         'BAM/%s.bam' % trio['child']]) + '\\n')\n",
    "    fid.write('\\t'.join([trio['father'], trio['famid'], '0', '0', '1',\n",
    "                         'BAM/%s.bam' % trio['father']]) + '\\n')\n",
    "    fid.write('\\t'.join([trio['mother'], trio['famid'], '0', '0', '2',\n",
    "                         'BAM/%s.bam' % trio['mother']]) + '\\n')\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm running it in a R terminal to have a better look at the output, but here's a history of the commands (following from https://github.com/JMF47/MDTS/blob/master/vignettes/mdts.Rmd):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "source('getMetaData.R')\n",
    "pD = getMetaData(\"../simplex84.ped\")\n",
    "\n",
    "library(BSgenome.Hsapiens.UCSC.hg19)\n",
    "genome = BSgenome.Hsapiens.UCSC.hg19; map_file = \"chr1.map.bw\"\n",
    "source('calcBins.R')\n",
    "setwd('../')\n",
    "bins = calcBins(pD, n=5, med=150, min=5, genome, map_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't tell yet if the chr1 file is enough, or if they need one per each chromosome. Also, need to check if this is the best reference file for us, and check if the other parameters are also appropriate.\n",
    "\n",
    "Based on the output I'm seeing so far, I'd need one map_file for each chromossome. For example, the output of calcBins looks like this so far:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> bins = calcBins(pD, n=5, med=150, min=5, genome, map_file)\n",
    "Reading coverage information of subsamples\n",
    "BAM/CLIA_400188.bam\n",
    "BAM/CLIA_400137.bam\n",
    "BAM/CLIA_400121.bam\n",
    "BAM/CLIA_400122.bam\n",
    "BAM/CLIA_400171.bam\n",
    "Calculating Proto-regions\n",
    "Selecting Proto-regions in Chr 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
