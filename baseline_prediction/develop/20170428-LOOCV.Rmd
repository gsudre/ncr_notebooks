---
title: "LOOCV"
output: html_notebook
---

I'm struggloing a bit on how to report the results. In a clinical setting, it would make sense to do a LOOCV, but not necessarily to train the model. Also, a single subject should take away much from finding the initial parameters. So, we could potentially just use the entire dataset to decide on algorithms and pre-processing, and then do a repeated 10fold after LOOCV for each subject. 

We'd have to save each model, or just the prediction probabilities, but then it should be easy enough to create the test metrics for the entire dataset.

Let's see what we can get by doing that. Using AD voxelwise as usual.

```{r}
myseed=1234
source('~/ncr_notebooks/baseline_prediction/src/aux_functions.R')
tract_data = read.csv('~/data/baseline_prediction/stripped/dti.csv')
load('~/data/baseline_prediction/dti/ad_voxelwise.RData')
dti_vdata = cbind(tract_data$maskid, ad_data)
gf_fname = '~/data/baseline_prediction/stripped/clinical.csv'
gf = read.csv(gf_fname)
gf_base = gf[gf$BASELINE=='BASELINE', ]
my_ids = intersect(gf_base$MRN, tract_data$MRN)
merged = mergeOnClosestDate(gf_base, tract_data, my_ids)
rm_me = abs(merged$dateX.minus.dateY.months) > 12
merged = merged[!rm_me, ]
dti_base_vdata = merge(merged$maskid, dti_vdata, by.x=1, by.y=1, all.y=F, all.x=T)

get_needed_residuals = function(y, fm_str, cutoff, merged) {
  fm = as.formula(fm_str)
  fit = lm(fm)
  # selecting which covariates to use
  fm = "y ~ "
  for (r in 2:dim(summary(fit)$coefficients)[1]) {
    if (summary(fit)$coefficients[r, 4] < cutoff) {
      cname = rownames(summary(fit)$coefficients)[r]
      cname = gsub("SEXMale", "SEX", cname)
      fm = sprintf('%s + %s', fm, cname)
    }
  }
  # don't do anything if no variables were significant
  if (fm == 'y ~ ') {
    return(y)
  } else {
    opt_fit = lm(as.formula(fm))
    return(opt_fit$residuals)
  }
}

X = dti_base_vdata[, 2:ncol(dti_base_vdata)]
rm_me = colSums(is.na(X)) > 0
X = X[, !rm_me]
keep_me = merged$age <= 12
X = X[keep_me, ]
y = merged$DX_BASELINE
y[y!='NV'] = 'ADHD'
y = factor(y, levels=c('ADHD', 'NV'))
y = y[keep_me]
library(parallel)
cl <- makeCluster(6)
X_resid = parSapply(cl, X, get_needed_residuals, 'y ~ merged$age_at_scan + I(merged$age_at_scan^2) + merged$SEX', .1, merged[keep_me, ])
stopCluster(cl)
X_resid = as.data.frame(X_resid)

library(parallel)
cl <- makeCluster(6)
pvals = parSapply(cl, X_resid, function(d, y) t.test(d ~ y)$p.value, y)
stopCluster(cl)
X_resid = X_resid[, which(pvals <= .05)]
print(dim(X_resid))

pp <- preProcess(X_resid, method = c('BoxCox', 'center', 'scale', 'pca'), thresh=.9)
filtX<- predict(pp, X_resid)
print(dim(filtX))

tuneLength=10
set.seed(myseed)
index <- createMultiFolds(ytrain, k = 10, times = 10)

set.seed(myseed)
fullCtrl <- trainControl(method = "repeatedcv",
                         index = index,
                         savePredictions="final",
                         classProbs=TRUE,
                         summaryFunction=twoClassSummary)

require(doMC)
registerDoMC(cores=6)
library(caretEnsemble)
full_model_list <- caretList(
  filtX, y,
  tuneLength=10,
  trControl=fullCtrl,
  metric='ROC',
  methodList=c('rf', 'kernelpls', 'svmRadial', 'knn', 'rpart', 'bagEarthGCV', 'LogitBoost', 'lda', 'nb')
  )

greedy_ensemble <- caretEnsemble(
  full_model_list,
  metric='ROC',
  trControl=trainControl(
    number=2,
    summaryFunction=twoClassSummary,
    classProbs=TRUE
    ))
# ROC stats
summary(greedy_ensemble)
```

Using the entire data, it's clear that PLS is doing the best:

```{r}
resamps = resamples(full_model_list)
bwplot(resamps, layout = c(3, 1))
difValues <- diff(resamps)
dotplot(difValues)
mcor = modelCor(resamps)
library(corrplot)
corrplot(mcor, order = "hclust", method='color', cl.lim=c(min(mcor), max(mcor)))
```

Now, say we do a LOOCV. How well do we predict the left out subject? It also makes sense to use the top 3 models that aren't too correlated, just so we can have some sort of voting scheme in case the probabilities are too close to call.

```{r}
myseed=1234
njobs=6
tuneLength=10
preds = c()
for (s in 1:1) {#length(y)) {
  print(sprintf('LO %d / %d', s, length(y)))
  Xtrain <- X_resid[ -s, ]
  ytrain <- y[ -s ]
  Xtest  <- X_resid[s, ]
  
  library(parallel)
  cl <- makeCluster(njobs)
  pvals = parSapply(cl, Xtrain, function(d, ytrain) t.test(d ~ ytrain)$p.value, ytrain)
  stopCluster(cl)
  Xtrain = Xtrain[, which(pvals <= .05)]
  keep_me = sapply(colnames(Xtrain), function(d) which(colnames(Xtest) == d))
  Xtest = Xtest[, keep_me]
  
  pp <- preProcess(Xtrain, method = c('BoxCox', 'center', 'scale', 'pca'), thresh=.9)
  filtXtrain<- predict(pp, Xtrain)
  filtXtest <- predict(pp, Xtest)
  
  set.seed(myseed)
  index <- createMultiFolds(ytrain, k = 10, times = 10)
  
  set.seed(myseed)
  fullCtrl <- trainControl(method = "boot",
                           index = index,
                           savePredictions="final",
                           classProbs=TRUE,
                           summaryFunction=twoClassSummary)
  
  require(doMC)
  registerDoMC(cores=njobs)
  library(caretEnsemble)
  model_list <- caretList(
    filtXtrain, ytrain,
    tuneLength=tuneLength,
    trControl=fullCtrl,
    metric='ROC',
    methodList=c('kernelpls', 'bagEarthGCV', 'knn')
  )
  preds = lapply(model_list, predict, newdata=filtXtest, type='prob')
  print(do.call(rbind, preds))
}
```

But this is taking too long. So, lets farm it in a subject level.

```{r}
preds = c()
preds2 = c()
a = read.table('~/tmp/all_3_varp6.txt')
start=1
while (start < length(y)*3) {
  adhd_prob = prod(a[start:(start+2),2], na.rm=T)
  nv_prob = prod(a[start:(start+2),3], na.rm=T)
  adhd_cnt = 0
  if (!is.na(sum(a[start, 2:3])) && (a[start, 2] > a[start, 3])) {
    adhd_cnt = adhd_cnt + 1
  }
  if (!is.na(sum(a[start+1, 2:3])) && (a[start+1, 2] > a[start+1, 3])) {
    adhd_cnt = adhd_cnt + 1
  }
  if (!is.na(sum(a[start+2, 2:3])) && (a[start+2, 2] > a[start+2, 3])) {
    adhd_cnt = adhd_cnt + 1
  }
  if (adhd_cnt >= 2) {
    preds2 = c(preds2, 'ADHD')
  } else {
    preds2 = c(preds2, 'NV')
  }
  start = start + 3
  if (adhd_prob > nv_prob) {
    preds = c(preds, 'ADHD')
  } else {
    preds = c(preds, 'NV')
  }
}
preds = factor(preds, levels=levels(y))
preds2 = factor(preds2, levels=levels(y))
```

# Other resampling methods
Let me play with other resampling methods first, using the entire dataset. Ideally we can reduce the variance a bit, even though we're already quite good with kernelpls. The other idea is to go for maximizing accuracy, as that seems to be a tough thing to sell.

```{r}
myseed=1234
source('~/ncr_notebooks/baseline_prediction/src/aux_functions.R')
tract_data = read.csv('~/data/baseline_prediction/stripped/dti.csv')
load('~/data/baseline_prediction/dti/ad_voxelwise.RData')
dti_vdata = cbind(tract_data$maskid, ad_data)
gf_fname = '~/data/baseline_prediction/stripped/clinical.csv'
gf = read.csv(gf_fname)
gf_base = gf[gf$BASELINE=='BASELINE', ]
my_ids = intersect(gf_base$MRN, tract_data$MRN)
merged = mergeOnClosestDate(gf_base, tract_data, my_ids)
rm_me = abs(merged$dateX.minus.dateY.months) > 12
merged = merged[!rm_me, ]
dti_base_vdata = merge(merged$maskid, dti_vdata, by.x=1, by.y=1, all.y=F, all.x=T)

get_needed_residuals = function(y, fm_str, cutoff, merged) {
  fm = as.formula(fm_str)
  fit = lm(fm)
  # selecting which covariates to use
  fm = "y ~ "
  for (r in 2:dim(summary(fit)$coefficients)[1]) {
    if (summary(fit)$coefficients[r, 4] < cutoff) {
      cname = rownames(summary(fit)$coefficients)[r]
      cname = gsub("SEXMale", "SEX", cname)
      fm = sprintf('%s + %s', fm, cname)
    }
  }
  # don't do anything if no variables were significant
  if (fm == 'y ~ ') {
    return(y)
  } else {
    opt_fit = lm(as.formula(fm))
    return(opt_fit$residuals)
  }
}

X = dti_base_vdata[, 2:ncol(dti_base_vdata)]
rm_me = colSums(is.na(X)) > 0
X = X[, !rm_me]
keep_me = merged$age <= 12
X = X[keep_me, ]
y = merged$DX_BASELINE
y[y!='NV'] = 'ADHD'
y = factor(y, levels=c('ADHD', 'NV'))
y = y[keep_me]
library(parallel)
cl <- makeCluster(6)
X_resid = parSapply(cl, X, get_needed_residuals, 'y ~ merged$age_at_scan + I(merged$age_at_scan^2) + merged$SEX', .1, merged[keep_me, ])
stopCluster(cl)
X_resid = as.data.frame(X_resid)

library(parallel)
cl <- makeCluster(6)
pvals = parSapply(cl, X_resid, function(d, y) t.test(d ~ y)$p.value, y)
stopCluster(cl)
X_resid = X_resid[, which(pvals <= .05)]
print(dim(X_resid))

pp <- preProcess(X_resid, method = c('BoxCox', 'center', 'scale', 'pca'), thresh=.9)
filtX<- predict(pp, X_resid)
print(dim(filtX))

tuneLength=10
set.seed(myseed)
index <- createMultiFolds(ytrain, k = 10, times = 10)

set.seed(myseed)
fullCtrl <- trainControl(method = "repeatedcv",
                         index = index,
                         savePredictions="final",
                         classProbs=TRUE)

require(doMC)
registerDoMC(cores=6)
library(caretEnsemble)
full_model_list <- caretList(
  filtX, y,
  tuneLength=10,
  trControl=fullCtrl,
  metric='Accuracy',
  methodList=c('rf', 'kernelpls', 'svmRadial', 'knn', 'rpart', 'bagEarthGCV', 'LogitBoost', 'lda', 'nb')
  )

greedy_ensemble <- caretEnsemble(
  full_model_list,
  metric='Accuracy',
  trControl=trainControl(
    number=2,
    classProbs=TRUE
    ))
# ROC stats
summary(greedy_ensemble)
```

Using the entire data, PLS still does the best:

```{r}
resamps = resamples(full_model_list)
bwplot(resamps, layout = c(3, 1))
difValues <- diff(resamps)
dotplot(difValues)
mcor = modelCor(resamps)
library(corrplot)
corrplot(mcor, order = "hclust", method='color', cl.lim=c(min(mcor), max(mcor)))
```

To quickly evaluate the swarmed loocv results:

```{r}
preds = c()
a = read.table('~/tmp/onePCAp6_sort.txt')
start=1
while (start <= length(y)) {
  adhd_prob = a[start,2]
  nv_prob = a[start,3]
  if (is.na(adhd_prob) || is.na(nv_prob)) {
    preds = c(preds, 'err')
  } else if (adhd_prob > nv_prob) {
    preds = c(preds, 'ADHD')
  } else {
    preds = c(preds, 'NV')
  }
  start = start+1
}
preds = factor(preds, levels=levels(y))
```

I don't really understand why such a good cross-validated model in training is performing so poorly in LOOCV... I need to take a closer look... let's check when it fails.

```{r}
myseed=1234
source('~/ncr_notebooks/baseline_prediction/src/aux_functions.R')
tract_data = read.csv('~/data/baseline_prediction/stripped/dti.csv')
load('~/data/baseline_prediction/dti/ad_voxelwise.RData')
dti_vdata = cbind(tract_data$maskid, ad_data)
gf_fname = '~/data/baseline_prediction/stripped/clinical.csv'
gf = read.csv(gf_fname)
gf_base = gf[gf$BASELINE=='BASELINE', ]
my_ids = intersect(gf_base$MRN, tract_data$MRN)
merged = mergeOnClosestDate(gf_base, tract_data, my_ids)
rm_me = abs(merged$dateX.minus.dateY.months) > 12
merged = merged[!rm_me, ]
dti_base_vdata = merge(merged$maskid, dti_vdata, by.x=1, by.y=1, all.y=F, all.x=T)

get_needed_residuals = function(y, fm_str, cutoff, merged) {
  fm = as.formula(fm_str)
  fit = lm(fm)
  # selecting which covariates to use
  fm = "y ~ "
  for (r in 2:dim(summary(fit)$coefficients)[1]) {
    if (summary(fit)$coefficients[r, 4] < cutoff) {
      cname = rownames(summary(fit)$coefficients)[r]
      cname = gsub("SEXMale", "SEX", cname)
      fm = sprintf('%s + %s', fm, cname)
    }
  }
  # don't do anything if no variables were significant
  if (fm == 'y ~ ') {
    return(y)
  } else {
    opt_fit = lm(as.formula(fm))
    return(opt_fit$residuals)
  }
}

X = dti_base_vdata[, 2:ncol(dti_base_vdata)]
rm_me = colSums(is.na(X)) > 0
X = X[, !rm_me]
keep_me = merged$age <= 12
X = X[keep_me, ]
y = merged$DX_BASELINE
y[y!='NV'] = 'ADHD'
y = factor(y, levels=c('ADHD', 'NV'))
y = y[keep_me]
library(parallel)
cl <- makeCluster(6)
X_resid = parSapply(cl, X, get_needed_residuals, 'y ~ merged$age_at_scan + I(merged$age_at_scan^2) + merged$SEX', .1, merged[keep_me, ])
stopCluster(cl)
X_resid = as.data.frame(X_resid)
```

```{r}
preds = c()
for (s in 1:1) {
  # we need to do the univariate filter first otherwise we will be doing pca
  # on garbage
  Xtrain <- X_resid[ -s, ]
  ytrain <- y[ -s ]
  Xtest  <- X_resid[s, ]
  
  library(parallel)
  cl <- makeCluster(njobs)
  pvals = parSapply(cl, Xtrain, function(d, ytrain) t.test(d ~ ytrain)$p.value, ytrain)
  stopCluster(cl)
  Xtrain = Xtrain[, which(pvals <= .05)]
  keep_me = sapply(colnames(Xtrain), function(d) which(colnames(Xtest) == d))
  Xtest = Xtest[, keep_me]
  
  pp <- preProcess(rbind(Xtrain, Xtest),
                   method = c('BoxCox', 'center', 'scale', 'pca'), thresh=.6)
  filtXtrain <- predict(pp, Xtrain)
  filtXtest <- predict(pp, Xtest)
  
  tuneLength=10
  set.seed(myseed)
  index <- createMultiFolds(ytrain, k=5, 200)
  
  require(doMC)
  registerDoMC(cores=6)
  set.seed(myseed)
  fullCtrl <- trainControl(method = "repeatedcv",
                           number=5,
                           repeats=200,
                           index = index,
                           savePredictions="final",
                           classProbs=TRUE)
  
  require(doMC)
  registerDoMC(cores=njobs)
  set.seed(myseed)
  mymod = train(filtXtrain, ytrain,
                tuneLength=10,
                trControl=fullCtrl,
                metric='Accuracy',
                method='svmRadial')
  
  # print(mymod)
  print(sprintf('LO %d / %d (%s)', s, length(y), y[s]))
  preds = c(preds, predict(mymod, newdata=filtXtest))
  print(preds)
}
```



