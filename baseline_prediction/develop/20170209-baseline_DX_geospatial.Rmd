---
title: "Analysis of geospatial and SES data"
output:
  html_notebook: default
  html_document: default
---

First, some data cleaning:

```{r}
# for replication purposes
set.seed(107)
library(caret)
source('~/ncr_notebooks/baseline_prediction/src/aux_functions.R')

# Philip pre-selected which structural scans to use
gf_fname = '~/data/baseline_prediction/gf_updated_02152017_3.csv'
gf = read.csv(gf_fname)
data_fname = '~/data/baseline_prediction/gustavo_PLS.csv'
geo_data = read.csv(data_fname)
data = merge(gf, geo_data, by.x='ID', by.y='MRN', all.x=F, all.Y=F)
group_var = 'DX2'
idx = data$BASELINE == 'BASELINE'
data = data[idx,]
eval(parse(text=sprintf('groups = data$\"%s\"', group_var)))
groups_orig = groups
```

Now it's a matter of selecting the variables we want to test. Because there are too many variables with NAs, and right now I don't have an intuition of whether imputation or removing subjects would work best. Let's do this within domain first, and evaluate in a per-domain basis.

# Philip's factors

These are the results from the PCA Philip ran:

```{r}
phen_vars = c('poverty_education', 'social_environment', 'physical_health_environment', 'physical_envronment')
keep_me = c()
for (v in phen_vars) {
  keep_me = c(keep_me, which(colnames(data) == v))
}
ldata_orig = data[, keep_me]
```

First we try some imputation:
```{r}
ldata = ldata_orig
groups = groups_orig
ncv = 5
nrepeatcv = 2
nsplits = 5
train_test_ratio = .85
root_fname = '~/tmp/GeoPCA_NVvsADHD'
sink(sprintf('%s.log', root_fname), append=FALSE, split=TRUE)
ncpus <- detectBatchCPUs()
njobs = ncpus - 1

run_models = c('rndForest', 'lr', 'rsvm', 'xgb') # c('rndForest', 'lr', 'lsvm', 'rsvm', 'xgb', 'gbm')

inTrain = createDataPartition(y = groups,
                              times= nsplits,
                              p=train_test_ratio)
metric = "ROC"
default_preproc = c("center", 'scale')
default_options = c()
ctrl_cv <- trainControl(method = "repeatedcv",
                        number = ncv,
                        repeats = nrepeatcv,
                        classProbs = TRUE,
                        returnData = FALSE,
                        summaryFunction = twoClassSummary,
                        preProcOptions = default_options,
                        search='grid')

source('~/ncr_notebooks/baseline_prediction/src/do_classification.R')
source('~/ncr_notebooks/baseline_prediction/src/do_metrics_plots.R')
sink()
```

But we should try the same analysis using the raw data:

```{r}
phen_vars = c('Home_Price', 'Fam_Income', 'Pop_BPL', 'Fam_BPL	Pub_School', 'Crime_Rate',
              'Green_Space', 'Park_Access', 'Air_Quality', 'Obesity_Rate', 'Food_Index',
              'Exercise_Access', 'Excessive_Drinking')
keep_me = c()
for (v in phen_vars) {
  keep_me = c(keep_me, which(colnames(data) == v))
}
ldata_orig = data[, keep_me]
```

```{r}
ldata = ldata_orig
groups = groups_orig
root_fname = '~/tmp/GeoRaw_NVvsADHD'
sink(sprintf('%s.log', root_fname), append=FALSE, split=TRUE)
inTrain = createDataPartition(y = groups,
                              times= nsplits,
                              p=train_test_ratio)
source('~/ncr_notebooks/baseline_prediction/src/do_classification.R')
source('~/ncr_notebooks/baseline_prediction/src/do_metrics_plots.R')
sink()
```

What if I do my own PCA in the raw values?

```{r}
ldata = ldata_orig
groups = groups_orig
ldata.pca <- prcomp(ldata, center=T, scale=T)
plot(ldata.pca, type = "l")
print(ldata.pca$sdev^2)  # these are the eignevalues
```

Like before, the elbow is at 3, but the eigenvalue threshold (1) is at 4. Let's try both.

```{r}
ldata = ldata.pca$x[, 1:3]
root_fname = '~/tmp/GeoRaw_PCAElbow_NVvsADHD'
sink(sprintf('%s.log', root_fname), append=FALSE, split=TRUE)
run_models = c('rndForest', 'lr', 'rsvm', 'xgb') # c('rndForest', 'lr', 'lsvm', 'rsvm', 'xgb', 'gbm')
inTrain = createDataPartition(y = groups,
                              times= nsplits,
                              p=train_test_ratio)
default_preproc = c("center", 'scale')
default_options = c()
ctrl_cv <- trainControl(method = "repeatedcv",
                        number = ncv,
                        repeats = nrepeatcv,
                        classProbs = TRUE,
                        returnData = FALSE,
                        summaryFunction = twoClassSummary,
                        preProcOptions = default_options,
                        search='grid')

source('~/ncr_notebooks/baseline_prediction/src/do_classification.R')
source('~/ncr_notebooks/baseline_prediction/src/do_metrics_plots.R')
sink()
```

```{r}
ldata = ldata.pca$x[, 1:4]
root_fname = '~/tmp/GeoRaw_PCAEV1_NVvsADHD'
sink(sprintf('%s.log', root_fname), append=FALSE, split=TRUE)
run_models = c('rndForest', 'lr', 'rsvm', 'xgb') # c('rndForest', 'lr', 'lsvm', 'rsvm', 'xgb', 'gbm')
inTrain = createDataPartition(y = groups,
                              times= nsplits,
                              p=train_test_ratio)
default_preproc = c("center", 'scale')
default_options = c()
ctrl_cv <- trainControl(method = "repeatedcv",
                        number = ncv,
                        repeats = nrepeatcv,
                        classProbs = TRUE,
                        returnData = FALSE,
                        summaryFunction = twoClassSummary,
                        preProcOptions = default_options,
                        search='grid')

source('~/ncr_notebooks/baseline_prediction/src/do_classification.R')
source('~/ncr_notebooks/baseline_prediction/src/do_metrics_plots.R')
sink()
```

Given that X did better, let's add SES to it and see if it improves:

```{r}
phen_vars = c('FSIQ')
keep_me = c()
for (v in phen_vars) {
  keep_me = c(keep_me, which(colnames(gf) == v))
}
ldata_orig = gf[, keep_me]
ldata_orig = as.data.frame(ldata_orig)
```

```{r}
ldata = ldata_orig
groups = groups_orig
preProcValues <- preProcess(ldata, method = c("medianImpute"))
ldata <- predict(preProcValues, ldata)
root_fname = '~/tmp/FSIQ_medianImputed_NVvsADHD'
sink(sprintf('%s.log', root_fname), append=FALSE, split=TRUE)
run_models = c('rndForest', 'lr')  # rsvm was taking a long-ass time, and xgb was crapping out
inTrain = createDataPartition(y = groups,
                              times= nsplits,
                              p=train_test_ratio)
source('~/ncr_notebooks/baseline_prediction/src/do_classification.R')
source('~/ncr_notebooks/baseline_prediction/src/do_metrics_plots.R')
sink()
```


