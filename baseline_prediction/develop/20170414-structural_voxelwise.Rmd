---
title: "Voxelwise thickness analysis"
output: html_notebook
---

In the same spirit of Philip's cortical trajectories paper, let's see if we can use voxelwise thickness data to predict outcome. 

```{r}
source('~/ncr_notebooks/baseline_prediction/src/aux_functions.R')
struct_data = read.csv('~/data/baseline_prediction/stripped/structural.csv')
load('~/data/baseline_prediction/struct_thickness.RData')
vdata = cbind(struct_data$Mask.ID...Scan, lh_thickness, rh_thickness)
rm(lh_thickness)
rm(rh_thickness)
gf_fname = '~/data/baseline_prediction/stripped/clinical.csv'
gf = read.csv(gf_fname)
gf_base = gf[gf$BASELINE=='BASELINE', ]
my_ids = intersect(gf_base$MRN, struct_data$MRN)
mstruct = mergeOnClosestDate(gf_base, struct_data, my_ids)
rm_me = abs(mstruct$dateX.minus.dateY.months) > 12
mstruct = mstruct[!rm_me, ]
struct_base_vdata = merge(mstruct$Mask.ID...Scan, vdata, by.x=1, by.y=1, all.y=F, all.x=T)
rm(vdata)
```

We'll start with the symptom slopes for kids with baseline assessment <= 12.

```{r}
X = struct_base_vdata[, 2:ncol(struct_base_vdata)]
rm_me = colSums(is.na(X)) > 0
X = X[, !rm_me]

y = vector()
keep_me = vector()
target_col = which(colnames(gf)=='SX_inatt')
for (s in mstruct$MRN) {
  if ((gf_base[gf_base$MRN==s,]$age <= 12) && (gf_base[gf_base$MRN==s, target_col] >= 2)) {
    idx = gf$MRN==s
    sx_slope = lm(gf[idx, target_col] ~ gf[idx, ]$age)$coefficients[2]
    keep_me = c(keep_me, which(mstruct$MRN == s))
    y = c(y, sx_slope)
  }
}
X = X[keep_me, ]

myseed = 1234

set.seed(myseed)
split <- createDataPartition(y, p = .8, list = FALSE)

Xtrain <- X[ split, ]
ytrain <- y[ split ]
Xtest  <- X[-split, ]
ytest = y[-split]

# in voxel analysis it's actually more costly to do the correlation in the entire set of variables
# then to run the for loop, so let's first reduce the variables to only the univariate ones
pvals = sapply(Xtrain, function(d) cor.test(d, ytrain)$p.value)
Xtrain = Xtrain[, which(pvals <= .05)]
print(dim(Xtrain))

# now we can remove correlated and non-informative variables
nzv = nearZeroVar(Xtrain)
print(nzv)
if (length(nzv) > 0) {
  Xtrain = Xtrain[, -nzv]
}
correlations = cor(Xtrain, use='na.or.complete')
# # library(corrplot)
# # corrplot(correlations, order = "hclust")
highCorr = findCorrelation(correlations, cutoff=.75)
print(length(highCorr))
if (length(highCorr) > 0) {
  Xtrain = Xtrain[, -highCorr]
}
print(dim(Xtrain))

keep_me = sapply(colnames(Xtrain), function(d) which(colnames(Xtest) == d))
Xtest = Xtest[, keep_me]
```

```{r}
cpuDiff=1
tuneLength=10
mymod='rf'

set.seed(myseed)
index <- createMultiFolds(ytrain, k = 5, times = 5)

library(doMC)
ncpus <- detectBatchCPUs()
njobs <- ncpus - cpuDiff
registerDoMC(njobs)

set.seed(myseed)
fullCtrl <- trainControl(method = "repeatedcv",
                         index = index,
                         savePredictions="final")
m1 <- train(Xtrain, ytrain,
            method = mymod,
            trControl = fullCtrl,
            tuneLength = tuneLength)
print(m1)
pred = predict(m1, Xtest)
print(postResample(pred, ytest))
print(sprintf('No information rate: RMSE=%f', postResample(mean(ytrain), ytest)[1]))
```
Judgin by the results in the cluster, neither training nor testing is better than the No Information rate. A few more things we can try:
 * do other methods do better with this filtering method of feature selection?
 * can we do better with wrapper methods instead?
 
Also, note that even when running rf I'm still using 11Gb of memory in a single core... making this a parallel thing will take some patience.

Because of how they're designed, regression trees and MARS won't be too succeptible to noisy predictors. In general, tree and rule-based models, MARS and lasso have implicit feature selection. Still, something on top of it might still make it better. See here for a few options: https://topepo.github.io/caret/train-models-by-tag.html#implicit-feature-selection

If none of these things help, even after using wrappers, we can try going back to the latent class outcomes (instead of symptom slopes), and also go back to some data cleaning.

Let's see how other methods perform:

```{r}
library(caretEnsemble)
model_list <- caretList(
  Xtrain, ytrain,
  tuneLength=10,
  trControl=fullCtrl,
  # when doing classification, also try 'LogitBoost', 'lda', and 'nb'
  methodList=c('rf', 'kernelpls', 'svmRadial', 'lasso', 'knn', 'rpart', 'bagEarthGCV')
  )

greedy_ensemble <- caretEnsemble(
  model_list, 
  trControl=trainControl(
    number=2
    ))

glm_ensemble <- caretStack(
  model_list,
  method="glm",
  trControl=trainControl(
    method="boot",
    number=10,
    savePredictions="final"
  )
)

gbm_ensemble <- caretStack(
  model_list,
  method="gbm",
  verbose=FALSE,
  tuneLength=10,
  trControl=trainControl(
    method="boot",
    number=10,
    savePredictions="final"
  )
)
summary(greedy_ensemble)
model_preds <- lapply(model_list, predict, newdata=Xtest)
model_preds <- lapply(model_preds, function(d, obs) postResample(d, obs)[1], obs=ytest)
model_preds <- data.frame(model_preds)
ens_preds <- predict(greedy_ensemble, newdata=Xtest)
model_preds$greedyE <- postResample(ens_preds, ytest)[1]
ens_preds <- predict(glm_ensemble, newdata=Xtest)
model_preds$glmE <- postResample(ens_preds, ytest)[1]
ens_preds <- predict(gbm_ensemble, newdata=Xtest)
model_preds$gbmE <- postResample(ens_preds, ytest)[1]
print(model_preds)
print(sprintf('No information rate: RMSE=%f', postResample(mean(ytrain), ytest)[1]))
```

Unfortunately, still no better than NIR:

```
The fit for each individual model on the RMSE is:
      method     RMSE    RMSESD
          rf 1.131591 0.2050840
   kernelpls 1.137326 0.1784456
   svmRadial 1.143541 0.2192830
       lasso 1.202993 0.2019095
         knn 1.154453 0.1949865
       rpart 1.380211 0.1950522
 bagEarthGCV 1.152649 0.2058560
> model_preds <- lapply(model_list, predict, newdata=Xtest)
> model_preds <- lapply(model_preds, function(d, obs) postResample(d, obs)[1], obs=ytest)
> model_preds <- data.frame(model_preds)
> ens_preds <- predict(greedy_ensemble, newdata=Xtest)
> model_preds$greedyE <- postResample(ens_preds, ytest)[1]
> ens_preds <- predict(glm_ensemble, newdata=Xtest)
> model_preds$glmE <- postResample(ens_preds, ytest)[1]
> ens_preds <- predict(gbm_ensemble, newdata=Xtest)
> model_preds$gbmE <- postResample(ens_preds, ytest)[1]
> print(model_preds)
          rf kernelpls svmRadial   lasso      knn    rpart bagEarthGCV  greedyE     glmE    gbmE
RMSE 1.13474  1.157259  1.097551 1.33807 1.210579 1.105219     1.14732 1.114986 1.114986 1.11766
> print(sprintf('No information rate: RMSE=%f', postResample(mean(ytrain), ytest)[1]))
[1] "No information rate: RMSE=1.105219"
```

Before we try wrapping methods, as they're more computationally intensive, let's see if we can do better with either HI slopes, or any of the two types of outcomes:

## HI slopes
```
The following models were ensembled: rf, kernelpls, svmRadial, lasso, knn, rpart, bagEarthGCV 
They were weighted: 
0.0871 1.7809 -0.0483 0.0045 0.5379 -0.6667 -0.1932 -0.245
The resulting RMSE is: 1.066
The fit for each individual model on the RMSE is: 
      method     RMSE    RMSESD
          rf 1.124613 0.2792615
   kernelpls 1.131770 0.2571158
   svmRadial 1.126083 0.2227381
       lasso 1.113390 0.2197021
         knn 1.169518 0.2944045
       rpart 1.279183 0.2866664
 bagEarthGCV 1.197799 0.2461084
> model_preds <- lapply(model_list, predict, newdata=Xtest)
> model_preds <- lapply(model_preds, function(d, obs) postResample(d, obs)[1], obs=ytest)
> model_preds <- data.frame(model_preds)
> ens_preds <- predict(greedy_ensemble, newdata=Xtest)
> model_preds$greedyE <- postResample(ens_preds, ytest)[1]
> ens_preds <- predict(glm_ensemble, newdata=Xtest)
> model_preds$glmE <- postResample(ens_preds, ytest)[1]
> ens_preds <- predict(gbm_ensemble, newdata=Xtest)
> model_preds$gbmE <- postResample(ens_preds, ytest)[1]
> print(model_preds)
            rf kernelpls svmRadial     lasso       knn     rpart bagEarthGCV   greedyE      glmE      gbmE
RMSE 0.8407827 0.9388144  1.018985 0.9893239 0.8517311 0.9022074   0.9533012 0.9113803 0.9113803 0.9275208
> print(sprintf('No information rate: RMSE=%f', postResample(mean(ytrain), ytest)[1]))
[1] "No information rate: RMSE=0.902207"
```
Here none of the models do too well in training, but rf and knn do a decent job in prediction. The ensembles don't. 

Note that ensemble results might perform better if I only choose uncorrelated models, or bump up the sampling for glm and gbm, but for now let's try other things.

## inatt3 outcomes
Just to have a better comparison to the results above, we'll restrict ourselves to kids < 12 y.o.
```{r}
X = struct_base_vdata[, 2:ncol(struct_base_vdata)]
rm_me = colSums(is.na(X)) > 0
X = X[, !rm_me]

keep_me = mstruct$age <= 12
X = X[keep_me, ]
y = mstruct$inatt3_named
y = factor(y, levels=c('low', 'medium', 'high'))
y = y[keep_me]

myseed = 1234
set.seed(myseed)
split <- createDataPartition(y, p = .8, list = FALSE)
Xtrain <- X[ split, ]
ytrain <- y[ split ]
Xtest  <- X[-split, ]
ytest = y[-split]

# in voxel analysis it's actually more costly to do the correlation in the entire set of variables
# then to run the for loop, so let's first reduce the variables to only the univariate ones
pvals = sapply(Xtrain, function(d) summary(aov(lm(d ~ ytrain)))[[1]][[5]][1])
Xtrain = Xtrain[, which(pvals <= .05)]
print(dim(Xtrain))

# now we can remove correlated and non-informative variables
nzv = nearZeroVar(Xtrain)
print(nzv)
if (length(nzv) > 0) {
  Xtrain = Xtrain[, -nzv]
}
correlations = cor(Xtrain, use='na.or.complete')
# # library(corrplot)
# # corrplot(correlations, order = "hclust")
highCorr = findCorrelation(correlations, cutoff=.75)
print(length(highCorr))
if (length(highCorr) > 0) {
  Xtrain = Xtrain[, -highCorr]
}
print(dim(Xtrain))

keep_me = sapply(colnames(Xtrain), function(d) which(colnames(Xtest) == d))
Xtest = Xtest[, keep_me]

tuneLength=10
set.seed(myseed)
index <- createMultiFolds(ytrain, k = 5, times = 5)

set.seed(myseed)
fullCtrl <- trainControl(method = "repeatedcv",
                         index = index,
                         savePredictions="final")

library(caretEnsemble)
model_list <- caretList(
  Xtrain, ytrain,
  tuneLength=10,
  trControl=fullCtrl,
  methodList=c('rf', 'kernelpls', 'svmRadial', 'knn', 'rpart', 'bagEarthGCV', 'LogitBoost', 'lda', 'nb')
  )

model_perf = data.frame(lapply(model_list, function(d) getTrainPerf(d)[1]))
names(model_perf) = names(model_list)
model_preds <- lapply(model_list, predict, newdata=Xtest)
model_preds <- lapply(model_preds, function(d, obs) postResample(d, obs)[1], obs=ytest)
model_preds <- data.frame(model_preds)
names(model_preds) = names(model_list)
print(model_perf)
print(model_preds)
print(sprintf('No information rate: Accuracy=%f', max(table(ytrain)/length(ytrain))))
```



## HI3 outcomes



Now we can do some wrapping feature selection to see if it does better than filtering. Note that we'll need to train the functions by themselves and then make a list, otherwise it won't work for ensembles:

```{r}
X = struct_base_vdata[, 2:ncol(struct_base_vdata)]
rm_me = colSums(is.na(X)) > 0
X = X[, !rm_me]

y = vector()
keep_me = vector()
target_col = which(colnames(gf)=='SX_inatt')
for (s in mstruct$MRN) {
  if ((gf_base[gf_base$MRN==s,]$age <= 12) && (gf_base[gf_base$MRN==s, target_col] >= 2)) {
    idx = gf$MRN==s
    sx_slope = lm(gf[idx, target_col] ~ gf[idx, ]$age)$coefficients[2]
    keep_me = c(keep_me, which(mstruct$MRN == s))
    y = c(y, sx_slope)
  }
}
X = X[keep_me, ]

myseed = 1234

set.seed(myseed)
split <- createDataPartition(y, p = .8, list = FALSE)

Xtrain <- X[ split, ]
ytrain <- y[ split ]
Xtest  <- X[-split, ]
ytest = y[-split]

varSeq = 1:10#ncol(X)
ctrl <- rfeControl(method = "repeatedcv",
                   saveDetails = TRUE,
                   index = index,
                   returnResamp = "final")
ctrl$functions <- rfFuncs
set.seed(myseed)
rfRFE <- rfe(Xtrain[1:10], ytrain,
             sizes = varSeq,
             rfeControl = ctrl,
             summaryFunction = defaultSummary)
ctrl$functions <- lmFuncs
set.seed(myseed)
lmRFE <- rfe(Xtrain[1:10], ytrain,
             sizes = varSeq,
             rfeControl = ctrl,
             summaryFunction = defaultSummary)


tbRFE

lrRFE

```







