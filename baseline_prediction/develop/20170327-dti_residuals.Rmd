---
title: "Analyzing DTI residuals"
output: html_notebook
---

Philip suggested we should use the residuals of regressing the brain variables on age and sex. It's worth a try. 

```{r}
source('~/ncr_notebooks/baseline_prediction/src/aux_functions.R')

tract_data = read.csv('~/data/baseline_prediction/stripped/dti.csv')
rm_me = (tract_data$fa_avg < .4 | tract_data$ad_avg < 1.18 | tract_data$rd_avg > .65 | tract_data$rd_avg < .5 |
         tract_data$norm.trans > .45 | tract_data$norm.rot > .008 | tract_data$goodSlices < 45 | tract_data$goodSlices > 70)
print(sprintf('Reducing from %d to %d scans', nrow(tract_data), nrow(tract_data)-sum(rm_me)))
tract_data = tract_data[!rm_me, ]
gf_fname = '~/data/baseline_prediction/stripped/clinical.csv'
gf = read.csv(gf_fname)
gf = gf[gf$BASELINE=='BASELINE', ]
my_ids = intersect(gf$MRN, tract_data$MRN)
merged = mergeOnClosestDate(gf, tract_data, my_ids)
rm_me = abs(merged$dateX.minus.dateY.months) > 12
print(sprintf('Reducing from %d to %d scans', nrow(merged), nrow(merged)-sum(rm_me)))
merged = merged[!rm_me, ]

phen_vars = c(which(grepl("^FA_", colnames(merged))),
              which(grepl("^AD_", colnames(merged))),
              which(grepl("^RD_", colnames(merged))),
              which(grepl("^MO_", colnames(merged)))
              )
X = merged[, phen_vars]
y = merged$DX_BASELINE
y[y != 'NV'] = 'ADHD'
y = factor(y)
rm_me = rowSums(is.na(X)) > 0
X = X[!rm_me, ]
merged = merged[!rm_me, ]
y = y[!rm_me]
X_resid = sapply(X, function(d) lm(d ~ merged$age_at_scan + merged$SEX)$residuals)
X_resid = as.data.frame(X_resid)
```

Now we start some ML shenanigans...

Let's first focus on the variables that have good T-stats for now. We will manually set them at first, but then we can do it within the CV loops:

```{r}
library(pROC)

phen_vars = c('FA_left_cst', 'FA_right_cst', 'FA_right_ifo', 'FA_right_ilf', 'FA_right_slf',
              'RD_right_slf', 'MO_left_ifo', 'MO_right_ifo', 'MO_right_ilf', 'MO_right_slf')
keep_me = sapply(phen_vars, function(d) which(colnames(X_resid) == d))
X = X_resid[, keep_me]

myseed = 1234
cpuDiff = 1
tuneLength = 10
default_preproc = c("center", 'scale')
set.seed(myseed)
split <- createDataPartition(y, p = .8, list = FALSE)

Xtrain <- X[ split, ]
ytrain <- y[ split ]
Xtest  <- X[-split, ]
ytest = y[-split]

set.seed(myseed)
index <- createMultiFolds(ytrain, k = 5, times = 5)

library(doMC)
ncpus <- detectBatchCPUs()
njobs <- ncpus - cpuDiff
registerDoMC(njobs)
selFunc = 'best'  # maybe try oneSE and tolerance as well?

set.seed(myseed)
fullCtrl <- trainControl(method = "repeatedcv",
                         index = index,
                         search='grid',
                         summaryFunction = twoClassSummary,
                         classProbs = TRUE)
rndForestGrid <- expand.grid(.mtry=c(1:sqrt(ncol(Xtrain))))
rfFull <- train(Xtrain, ytrain,
                method = "rf",
                trControl = fullCtrl,
                tuneGrid=rndForestGrid,
                metric = 'ROC',
                preProcess = default_preproc)
  
getTrainPerf(rfFull)
pred = predict(rfFull, Xtest)
postResample(pred, ytest)
roc(as.numeric(ytest), as.numeric(pred))
```

Very underwhelming results... let's see what we can get with symptom regression. None of them has a significant correlation to symptoms, so let's include everything.

```{r}
thresh = 1
keep_me = merged$SX_inatt >= thresh & merged$SX_HI >= thresh
X = X_resid[keep_me,]
y = merged[keep_me,]$SX_inatt

myseed = 1234
cpuDiff = 1
tuneLength = 10
default_preproc = c("center", 'scale')
set.seed(myseed)
split <- createDataPartition(y, p = .8, list = FALSE)

Xtrain <- X[ split, ]
ytrain <- y[ split ]
Xtest  <- X[-split, ]
ytest = y[-split]

set.seed(myseed)
index <- createMultiFolds(ytrain, k = 5, times = 5)

library(doMC)
ncpus <- detectBatchCPUs()
njobs <- ncpus - cpuDiff
registerDoMC(njobs)
selFunc = 'best'  # maybe try oneSE and tolerance as well?

set.seed(myseed)
fullCtrl <- trainControl(method = "repeatedcv",
                         index = index,
                         search='grid',
                         summaryFunction = defaultSummary)
rndForestGrid <- expand.grid(.mtry=c(1:sqrt(ncol(Xtrain))))
rfFull <- train(Xtrain, ytrain,
                method = "rf",
                trControl = fullCtrl,
                tuneGrid=rndForestGrid,
                preProcess = default_preproc)
  
rfFull
pred = predict(rfFull, Xtest)
postResample(pred, ytest)

varSeq = 1:ncol(X)
ctrl <- rfeControl(method = "repeatedcv",
                   saveDetails = TRUE,
                   index = index,
                   returnResamp = "final")

ctrl$functions <- rfFuncs
set.seed(myseed)
rfRFE <- rfe(Xtrain, ytrain,
             sizes = varSeq,
             rfeControl = ctrl,
             preProcess = default_preproc,
             summaryFunction = defaultSummary)
rfRFE
pred = predict(rfRFE, Xtest)
postResample(pred, ytest)
```

It's interesting that by removing the 0/0s we get an improvement in symptom regression. That's what I expected. But is the residualizing process doing anything?

```{r}
thresh = 1
keep_me = merged$SX_inatt >= thresh & merged$SX_HI >= thresh
X = X_resid[keep_me,]
y = merged[keep_me,]$SX_inatt

myseed = 1234
cpuDiff = 1
tuneLength = 10
default_preproc = c("center", 'scale')
set.seed(myseed)
split <- createDataPartition(y, p = .8, list = FALSE)

Xtrain <- X[ split, ]
ytrain <- y[ split ]
Xtest  <- X[-split, ]
ytest = y[-split]

set.seed(myseed)
index <- createMultiFolds(ytrain, k = 5, times = 5)

library(doMC)
ncpus <- detectBatchCPUs()
njobs <- ncpus - cpuDiff
registerDoMC(njobs)
selFunc = 'best'  # maybe try oneSE and tolerance as well?

set.seed(myseed)
fullCtrl <- trainControl(method = "repeatedcv",
                         index = index,
                         search='grid',
                         summaryFunction = defaultSummary)
rndForestGrid <- expand.grid(.mtry=c(1:sqrt(ncol(Xtrain))))
rfFull <- train(Xtrain, ytrain,
                method = "rf",
                trControl = fullCtrl,
                tuneGrid=rndForestGrid,
                preProcess = default_preproc)
  
rfFull
pred = predict(rfFull, Xtest)
postResample(pred, ytest)

varSeq = 1:ncol(X)
ctrl <- rfeControl(method = "repeatedcv",
                   saveDetails = TRUE,
                   index = index,
                   returnResamp = "final")

ctrl$functions <- rfFuncs
set.seed(myseed)
rfRFE <- rfe(Xtrain, ytrain,
             sizes = varSeq,
             rfeControl = ctrl,
             preProcess = default_preproc,
             summaryFunction = defaultSummary)
rfRFE
pred = predict(rfRFE, Xtest)
postResample(pred, ytest)
```

# Residualizing when necessary

Let's look into residualizing a variable only when it's significant, similar to what SOLAR does.

```{r}
get_needed_residuals = function(y, fm_str, cutoff) {
  fm = as.formula(fm_str)
  fit = lm(fm)
  # selecting which covariates to use
  fm = "y ~ "
  for (r in 2:dim(summary(fit)$coefficients)[1]) {
    if (summary(fit)$coefficients[r, 4] < cutoff) {
      cname = rownames(summary(fit)$coefficients)[r]
      cname = gsub("SEXMale", "SEX", cname)
      fm = sprintf('%s + %s', fm, cname)
    }
  }
  # don't do anything if no variables were significant
  if (fm == 'y ~ ') {
    return(y)
  } else {
    opt_fit = lm(as.formula(fm))
    return(opt_fit$residuals)
  }
}

X = merged[, phen_vars]
y = merged$DX_BASELINE
y[y != 'NV'] = 'ADHD'
y = factor(y)
rm_me = rowSums(is.na(X)) > 0
X = X[!rm_me, ]
merged = merged[!rm_me, ]
y = y[!rm_me]

X_resid = sapply(X, get_needed_residuals, 'y ~ merged$age_at_scan + I(merged$age_at_scan^2) + merged$SEX', .1)
X_resid = as.data.frame(X_resid)
```

Let's first run the results without removing the components, and then the residualized ones:

```{r}
myseed = 34
cpuDiff = 1
tuneLength = 10
default_preproc = c("center", 'scale')
set.seed(myseed)
split <- createDataPartition(y, p = .8, list = FALSE)

Xtrain <- X[ split, ]
ytrain <- y[ split ]
Xtest  <- X[-split, ]
ytest = y[-split]

set.seed(myseed)
index <- createMultiFolds(ytrain, k = 5, times = 5)

library(doMC)
ncpus <- detectBatchCPUs()
njobs <- ncpus - cpuDiff
registerDoMC(njobs)
selFunc = 'best'  # maybe try oneSE and tolerance as well?

set.seed(myseed)
fullCtrl <- trainControl(method = "repeatedcv",
                         index = index,
                         search='grid',
                         summaryFunction = twoClassSummary,
                         classProbs = TRUE)
rndForestGrid <- expand.grid(.mtry=c(1:sqrt(ncol(Xtrain))))
rfFull <- train(Xtrain, ytrain,
                method = "rf",
                trControl = fullCtrl,
                tuneGrid=rndForestGrid,
                metric = 'ROC',
                preProcess = default_preproc)
  
getTrainPerf(rfFull)
pred = predict(rfFull, Xtest)
postResample(pred, ytest)
roc(as.numeric(ytest), as.numeric(pred))
```

```{r}
Xtrain <- X_resid[ split, ]
ytrain <- y[ split ]
Xtest  <- X_resid[-split, ]
ytest = y[-split]

set.seed(myseed)
index <- createMultiFolds(ytrain, k = 5, times = 5)

library(doMC)
ncpus <- detectBatchCPUs()
njobs <- ncpus - cpuDiff
registerDoMC(njobs)
selFunc = 'best'  # maybe try oneSE and tolerance as well?

set.seed(myseed)
fullCtrl <- trainControl(method = "repeatedcv",
                         index = index,
                         search='grid',
                         summaryFunction = twoClassSummary,
                         classProbs = TRUE)
rndForestGrid <- expand.grid(.mtry=c(1:sqrt(ncol(Xtrain))))
rfFull <- train(Xtrain, ytrain,
                method = "rf",
                trControl = fullCtrl,
                tuneGrid=rndForestGrid,
                metric = 'ROC',
                preProcess = default_preproc)
  
getTrainPerf(rfFull)
pred = predict(rfFull, Xtest)
postResample(pred, ytest)
roc(as.numeric(ytest), as.numeric(pred))
```

It did better in training for a given seed, but not in testing. Let's try other seeds... that's the pattern I saw across seeds. It might be worth removing it later to se if results still hold? Not sure. Results were inconclusive, at least for DTI. Need to run it for the entire set, and for a distribution of seeds.



